{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq model with Attention mechanism\n",
    "\n",
    "[參考網址](https://github.com/soloice/tf-tutorial/blob/master/src/att_seq2seq_delete_and_copy.py)\n",
    "\n",
    "##### 註：註解掉的部分為使用tensorboard才須執行的部分，若欲嘗試tensorboard也可將註解還原"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# import argparse\n",
    "# from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "# parser.add_argument(\n",
    "#     \"--copy\",\n",
    "#     type=bool,\n",
    "#     default=True,\n",
    "#     help=\"Whether or not to copy the sequence.\")\n",
    "# FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# only the parameter (origin FLAGS.copy) below would be used (where copying sequence or not)\n",
    "cp_sequence = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_matrix(src, tgt, matrix,\n",
    "                          name=\"attention_matrix.png\"):\n",
    "    src = [str(item) for item in src]\n",
    "    tgt = [str(item) for item in tgt]\n",
    "    df = pd.DataFrame(matrix, index=src, columns=tgt)\n",
    "    ax = sns.heatmap(df, linewidths=.5)\n",
    "    ax.set_xlabel(\"target\")\n",
    "    ax.set_ylabel(\"source\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    ax.set_title(\"Attention heatmap\")\n",
    "    plt.savefig(name, bbox_inches='tight')\n",
    "    plt.gcf().clear()\n",
    "#     plt.show()\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10 + 1 # 1~10 + 0\n",
    "max_len = 48 # original max_len = 24, but the difference with/without attention is more subtle on acc\n",
    "MAX_DECODE_STEP = max_len + 5\n",
    "batch_size = 64\n",
    "lr = 1e-2\n",
    "PAD = 0\n",
    "EOS = 0\n",
    "GO = 0\n",
    "\n",
    "odd_list, even_list = [1, 3, 5, 7, 9] * 10, [2, 4, 6, 8, 10] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_x：產生隨機的奇偶數字(1~10，長度為2~max(len))，並且做padding使資料長度皆相同\n",
    "output_y：只回傳input_x中偶數的部分(順序需相同，另外若copy_sequence=True時會需複製兩次)\n",
    "          最後加入一個\"0\" 作為停止符號。亦作padding使資料長度相同\n",
    "\n",
    "註：在此為簡化狀況，PAD的數字亦為0 (請見上個cell的參數設定)\n",
    "\n",
    "length_x：回傳每個x的長度(未做padding前)\n",
    "length_y：回傳每個y的長度(未做padding前)，長度為 length_x+1 (copy_sequence=False) | length_x*2+1 (copy_sequence=True)\n",
    "'''\n",
    "\n",
    "def generate_data(num_samples=batch_size, copy_sequence=True):\n",
    "    num_odds = np.random.randint(low=1, high=max_len//2, size=num_samples)\n",
    "    num_evens = np.random.randint(low=1, high=max_len//2, size=num_samples)\n",
    "    batch_len_x = num_odds + num_evens\n",
    "    if copy_sequence:\n",
    "        batch_len_y = num_evens * 2 + 1  # append <EOS> (or prepend <GO>)\n",
    "    else:\n",
    "        batch_len_y = num_evens + 1  # append <EOS> (or prepend <GO>)\n",
    "\n",
    "    batch_max_length_x = np.max(batch_len_x)\n",
    "    batch_max_length_y = np.max(batch_len_y)\n",
    "\n",
    "    batch_data_x, batch_data_y = [], []\n",
    "    for i in range(num_samples):\n",
    "        odds = random.sample(odd_list, num_odds[i])\n",
    "        evens = random.sample(even_list, num_evens[i])\n",
    "        sample_x = odds + evens\n",
    "        random.shuffle(sample_x)\n",
    "\n",
    "        sample_y = list(filter(lambda x: x % 2 == 0, sample_x))\n",
    "        if copy_sequence:\n",
    "            sample_y += sample_y\n",
    "        sample_x = np.r_[sample_x, [PAD] * (batch_max_length_x - len(sample_x))]\n",
    "        sample_y = np.r_[sample_y, [EOS], [PAD] * (batch_max_length_y - len(sample_y) - 1)]\n",
    "\n",
    "        batch_data_x.append(sample_x)\n",
    "        batch_data_y.append(sample_y)\n",
    "\n",
    "    batch_data_x = np.array(batch_data_x, dtype=np.int32)\n",
    "    batch_data_y = np.array(batch_data_y, dtype=np.int32)\n",
    "\n",
    "    return batch_data_x, batch_data_y, batch_len_x, batch_len_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"attention-seq2seq/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "picture_path = os.path.join(save_path, \"pics\")\n",
    "if not os.path.exists(picture_path):\n",
    "    os.mkdir(picture_path)\n",
    "\n",
    "model_path = os.path.join(save_path, \"model\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "\n",
    "label_file_name = \"labels.tsv\"\n",
    "with open(os.path.join(model_path, label_file_name), \"w\") as f:\n",
    "    f.write(\"Number\\tIsOdd\\n\")\n",
    "    for i in range(vocab_size):\n",
    "        f.write(str(i) + \"\\t\" + str(i%2) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'encoder/seq2seq_encoder/while/Exit_2:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'encoder/seq2seq_encoder/while/Exit_3:0' shape=(?, 50) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'encoder/seq2seq_encoder/while/Exit_4:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'encoder/seq2seq_encoder/while/Exit_5:0' shape=(?, 50) dtype=float32>))\n",
      "logits:  Tensor(\"decoder/decoder/transpose:0\", shape=(64, ?, 11), dtype=float32)\n",
      "Tensor(\"Reshape_2:0\", shape=(64, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "encoder_embedding_size, decoder_embedding_size = 30, 30\n",
    "encoder_hidden_units, decoder_hidden_units = 50, 50\n",
    "attention_depth = decoder_hidden_units\n",
    "encoder_lstm_layers, decoder_lstm_layers = 2, 2\n",
    "\n",
    "# [B, T]\n",
    "encoder_inputs = tf.placeholder(shape=[None, None], dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=[None, None], dtype=tf.int32, name='decoder_targets')\n",
    "decoder_inputs = tf.placeholder(shape=[None, None], dtype=tf.int32, name='decoder_inputs')\n",
    "encoder_length = tf.placeholder(shape=[None], dtype=tf.int32, name='encoder_length')\n",
    "decoder_length = tf.placeholder(shape=[None], dtype=tf.int32, name='decoder_length')\n",
    "\n",
    "\n",
    "encoder_embedding_matrix = tf.Variable(tf.truncated_normal([vocab_size, encoder_embedding_size],\n",
    "                                                           mean=0.0, stddev=0.1),\n",
    "                                       dtype=tf.float32, name=\"encoder_embedding_matrix\")\n",
    "\n",
    "decoder_embedding_matrix = tf.Variable(tf.truncated_normal([vocab_size, decoder_embedding_size],\n",
    "                                                           mean=0.0, stddev=0.1),\n",
    "                                       dtype=tf.float32, name=\"decoder_embedding_matrix\")\n",
    "\n",
    "tf.summary.histogram(\"embeddings\", encoder_embedding_matrix)\n",
    "\n",
    "# [B, T, D]\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(encoder_embedding_matrix, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(decoder_embedding_matrix, decoder_inputs)\n",
    "\n",
    "with tf.variable_scope(\"encoder\"):\n",
    "    encoder_layers = [tf.contrib.rnn.BasicLSTMCell(encoder_hidden_units)\n",
    "                      for _ in range(encoder_lstm_layers)]\n",
    "    encoder = tf.contrib.rnn.MultiRNNCell(encoder_layers)\n",
    "\n",
    "    encoder_all_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "        encoder, encoder_inputs_embedded,\n",
    "        sequence_length=encoder_length,\n",
    "        dtype=tf.float32, time_major=False, scope=\"seq2seq_encoder\")\n",
    "    print(encoder_final_state)\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"decoder\"):\n",
    "    decoder_layers = [tf.contrib.rnn.BasicLSTMCell(encoder_hidden_units)\n",
    "                      for _ in range(decoder_lstm_layers)]\n",
    "    decoder = tf.contrib.rnn.MultiRNNCell(decoder_layers)\n",
    "\n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "        num_units=attention_depth,\n",
    "        memory=encoder_all_outputs,\n",
    "        memory_sequence_length=encoder_length)\n",
    "\n",
    "    attn_decoder = tf.contrib.seq2seq.AttentionWrapper(\n",
    "        decoder, attention_mechanism,\n",
    "        # cell_input_fn=lambda inputs, attention: inputs,\n",
    "        alignment_history=True, output_attention=True)\n",
    "\n",
    "    fc_layer = tf.layers.Dense(vocab_size)\n",
    "\n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(decoder_inputs_embedded,\n",
    "                                                        decoder_length)\n",
    "\n",
    "    decoder_initial_state = attn_decoder.zero_state(batch_size, tf.float32).clone(\n",
    "        cell_state=encoder_final_state)\n",
    "\n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        cell=attn_decoder, helper=training_helper,\n",
    "        initial_state=decoder_initial_state, output_layer=fc_layer)\n",
    "\n",
    "    logits, final_state, final_sequence_lengths = \\\n",
    "        tf.contrib.seq2seq.dynamic_decode(training_decoder)\n",
    "\n",
    "    # decoder_logits: [B, T, V]\n",
    "    decoder_logits = logits.rnn_output\n",
    "    # [decoder_steps, batch_size, encoder_steps]\n",
    "    attention_matrices = final_state.alignment_history.stack(\n",
    "        name=\"train_attention_matrix\")\n",
    "    print(\"logits: \", decoder_logits)\n",
    "\n",
    "\n",
    "# [B, T]\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits)\n",
    "print(stepwise_cross_entropy)\n",
    "\n",
    "mask = tf.sequence_mask(decoder_length,\n",
    "                        maxlen=tf.reduce_max(decoder_length),\n",
    "                        dtype=tf.float32)\n",
    "\n",
    "loss = tf.reduce_sum(stepwise_cross_entropy * mask) / tf.reduce_sum(mask)\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "# default setting is 1e-3 , but the model can converge more quickly when setting lr = 1e-2 (converge within 1500 epoch)\n",
    "# (ther's no issue of overfitting)\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "####### inference mode\n",
    "\n",
    "num_sequences_to_decode = tf.placeholder(shape=(), dtype=tf.int32, name=\"num_seq\")\n",
    "start_tokens = tf.tile([GO], [num_sequences_to_decode])\n",
    "inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "    decoder_embedding_matrix, start_tokens, end_token=EOS)\n",
    "\n",
    "inference_decoder_initial_state = attn_decoder.zero_state(\n",
    "    num_sequences_to_decode, tf.float32).clone(\n",
    "    cell_state=encoder_final_state)\n",
    "\n",
    "greedy_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    cell=attn_decoder, helper=inference_helper,\n",
    "    initial_state=inference_decoder_initial_state, output_layer=fc_layer)\n",
    "\n",
    "greedy_decoding_result, greedy_final_state, _2 = tf.contrib.seq2seq.dynamic_decode(\n",
    "    decoder=greedy_decoder, output_time_major=False,\n",
    "    impute_finished=True, maximum_iterations=MAX_DECODE_STEP)\n",
    "\n",
    "# [decoder_steps, batch_size, encoder_steps]\n",
    "inference_attention_matrices = greedy_final_state.alignment_history.stack(\n",
    "    name=\"inference_attention_matrix\")\n",
    "\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#產生decoder input & output  (timestep 平移 + GO)\n",
    "def get_decoder_input_and_output(ids):\n",
    "    B, T = ids.shape\n",
    "    go_ids = np.c_[np.zeros([B, 1], dtype=np.int32) + GO, ids]\n",
    "    return go_ids[:, :-1], go_ids[:, 1:]\n",
    "\n",
    "def draw_samples(session, number_samples_to_draw=3, global_step=-1):\n",
    "\n",
    "    x, y, lx, ly = generate_data(num_samples=number_samples_to_draw,\n",
    "                                 copy_sequence= cp_sequence) #FLAGS.copy)\n",
    "    feed = {encoder_inputs: x,\n",
    "            encoder_length: lx,\n",
    "            num_sequences_to_decode: number_samples_to_draw}\n",
    "    greedy_prediction, att_mat = session.run(\n",
    "        [greedy_decoding_result, inference_attention_matrices], feed_dict=feed)\n",
    "\n",
    "    np.set_printoptions(precision=2, linewidth=1000)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Sample x:\")\n",
    "    print(x)\n",
    "    print(\"Expected y:\")\n",
    "    print(y)\n",
    "    print(\"Greedy Decoding result:\")\n",
    "    y_ = greedy_prediction.sample_id\n",
    "    print(y_)\n",
    "\n",
    "    # 随机取一个样本 i 画出注意力矩阵\n",
    "    i = np.random.randint(low=1, high=number_samples_to_draw)\n",
    "    # matrix[k, l] -> encoder step `k` vs. decoder step `l`\n",
    "    matrix = att_mat[:, i, :].T\n",
    "    y_len = y_.shape[1]\n",
    "    for idx in range(y_.shape[1]):\n",
    "        if y_[i, idx] == 0:\n",
    "            y_len = idx + 1\n",
    "            break\n",
    "    x_valid = x[i, :lx[i]]\n",
    "    y_valid = y_[i, :y_len]\n",
    "    # print(x_valid)\n",
    "    # print(y_valid)\n",
    "    file_name = os.path.join(picture_path,\n",
    "                             \"attention_matrix-\" + str(global_step) + \".png\")\n",
    "    plot_attention_matrix(src=x_valid, tgt=y_valid,\n",
    "                          matrix=matrix[:lx[i], :y_len],\n",
    "                          name=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batches = 5001\n",
    "save_period = 100\n",
    "model_loss = []\n",
    "save_model = False\n",
    "restore_model = False\n",
    "\n",
    "if save_model:\n",
    "    saver = tf.train.Saver()\n",
    "    model_name = os.path.join(model_path, \"att-seq2seq\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if save_model:\n",
    "        train_writer = tf.summary.FileWriter(model_path, sess.graph)\n",
    "    \n",
    "    start_step = 0\n",
    "    if restore_model:\n",
    "        name = tf.train.latest_checkpoint(model_path)\n",
    "        if name is not None:\n",
    "            print(\"Restore from file \" + name)\n",
    "            saver.restore(sess, save_path=name)\n",
    "            start_step = int(name.split(\"-\")[-1]) + 1\n",
    "        else:\n",
    "            print(\"No previous checkpoints!\")\n",
    "\n",
    "    for batch_id in range(start_step, max_batches):\n",
    "        x, y, lx, ly = generate_data(copy_sequence= cp_sequence) #FLAGS.copy)\n",
    "        y_in, y_out = get_decoder_input_and_output(y)\n",
    "        # print(x, y, lx, ly, y_in, y_out)\n",
    "        feed = {encoder_inputs: x,\n",
    "                decoder_inputs: y_in,\n",
    "                decoder_targets: y_out,\n",
    "                encoder_length: lx,\n",
    "                decoder_length: ly}\n",
    "        dec_logits, _, loss_, att, summaries = sess.run(\n",
    "            [decoder_logits,train_op, loss, attention_matrices, merged_summary],\n",
    "            feed_dict=feed)\n",
    "        model_loss.append(loss_)\n",
    "        \n",
    "        if save_model:\n",
    "            train_writer.add_summary(summary=summaries,\n",
    "                                     global_step=batch_id)\n",
    "\n",
    "        if batch_id % save_period == 0:\n",
    "            if save_model:\n",
    "                saver.save(sess, save_path=model_name, global_step=batch_id)\n",
    "            print('batch {}'.format(batch_id))\n",
    "            print('  minibatch loss: {}'.format(loss_))\n",
    "            draw_samples(session=sess, global_step=batch_id)\n",
    "    if save_model:\n",
    "        train_writer.close()\n",
    "\n",
    "    print(\"Finish training!\")\n",
    "    draw_samples(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_loss)\n",
    "plt.title('Traning Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
